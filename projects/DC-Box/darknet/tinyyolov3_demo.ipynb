{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFPcBuVFw61h"
   },
   "source": [
    "# Overview\n",
    "\n",
    "This colab demonstrates the steps to use the DeepLab model to perform semantic segmentation on a sample input image. Expected outputs are semantic labels overlayed on the sample image.\n",
    "\n",
    "### About DeepLab\n",
    "The models used in this colab perform semantic segmentation. Semantic segmentation models focus on assigning semantic labels, such as sky, person, or car, to multiple objects and stuff in a single image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cRiapZ1P3wy"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "kAbdmRmvq0Je"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "import tarfile\n",
    "import tempfile\n",
    "from six.moves import urllib\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "#%tensorflow_version 1.x\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p47cYGGOQE1W"
   },
   "source": [
    "## Import helper methods\n",
    "These methods help us perform the following tasks:\n",
    "* Load the pretrained DeepLab model\n",
    "* Load the colormap from the PASCAL VOC dataset\n",
    "* Adds colors to various labels\n",
    "* Visualize an image, and add an overlay of colors on various regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "vN0kU6NJ1Ye5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import gfile\n",
    "class TinyYoloV3Model(object):\n",
    "  \"\"\"Class to load model and run inference.\"\"\"\n",
    "\n",
    "  INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "  OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "  INPUT_SIZE = 513\n",
    "  FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
    "\n",
    "  def __init__(self, model_path):\n",
    "    \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
    "    self.graph = tf.Graph()\n",
    "\n",
    "    file_handle = gfile.FastGFile(model_path,'rb')\n",
    "    graph_def = tf.GraphDef.FromString(file_handle.read())\n",
    "\n",
    "    if graph_def is None:\n",
    "      raise RuntimeError('Cannot find inference graph in archive.')\n",
    "\n",
    "    with self.graph.as_default():\n",
    "      tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    self.sess = tf.Session(graph=self.graph)\n",
    "  \n",
    "  def entry_index(side, coord, classes, location, entry):\n",
    "    side_power_2 = side ** 2\n",
    "    n = location // side_power_2\n",
    "    loc = location % side_power_2\n",
    "    return int(side_power_2 * (n * (coord + classes + 1) + entry) + loc)\n",
    "\n",
    "  def scale_bbox(x, y, h, w, class_id, confidence, h_scale, w_scale):\n",
    "    xmin = int((x - w / 2) * w_scale)\n",
    "    ymin = int((y - h / 2) * h_scale)\n",
    "    xmax = int(xmin + w * w_scale)\n",
    "    ymax = int(ymin + h * h_scale)\n",
    "    return dict(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax, class_id=class_id, confidence=confidence)\n",
    "\n",
    "  def intersection_over_union(box_1, box_2):\n",
    "    width_of_overlap_area = min(box_1['xmax'], box_2['xmax']) - max(box_1['xmin'], box_2['xmin'])\n",
    "    height_of_overlap_area = min(box_1['ymax'], box_2['ymax']) - max(box_1['ymin'], box_2['ymin'])\n",
    "    if width_of_overlap_area < 0 or height_of_overlap_area < 0:\n",
    "      area_of_overlap = 0\n",
    "    else:\n",
    "      area_of_overlap = width_of_overlap_area * height_of_overlap_area\n",
    "    box_1_area = (box_1['ymax'] - box_1['ymin']) * (box_1['xmax'] - box_1['xmin'])\n",
    "    box_2_area = (box_2['ymax'] - box_2['ymin']) * (box_2['xmax'] - box_2['xmin'])\n",
    "    area_of_union = box_1_area + box_2_area - area_of_overlap\n",
    "    if area_of_union == 0:\n",
    "      return 0\n",
    "    return area_of_overlap / area_of_union\n",
    "\n",
    "  def parse_yolo_region(blob, resized_image_shape, original_im_shape, params, threshold):\n",
    "    # ------------------------------------------ Validating output parameters ------------------------------------------\n",
    "    _, _, out_blob_h, out_blob_w = blob.shape\n",
    "    assert out_blob_w == out_blob_h, \"Invalid size of output blob. It sould be in NCHW layout and height should \" \\\n",
    "                     \"be equal to width. Current height = {}, current width = {}\" \\\n",
    "                     \"\".format(out_blob_h, out_blob_w)\n",
    "\n",
    "    # ------------------------------------------ Extracting layer parameters -------------------------------------------\n",
    "    orig_im_h, orig_im_w = original_im_shape\n",
    "    resized_image_h, resized_image_w = resized_image_shape\n",
    "    objects = list()\n",
    "    predictions = blob.flatten()\n",
    "    side_square = params.side * params.side\n",
    "\n",
    "    # ------------------------------------------- Parsing YOLO Region output -------------------------------------------\n",
    "    for i in range(side_square):\n",
    "      row = i // params.side\n",
    "      col = i % params.side\n",
    "      for n in range(params.num):\n",
    "        obj_index = TinyYOLOv3.entry_index(params.side, params.coords, params.classes, n * side_square + i, params.coords)\n",
    "        scale = predictions[obj_index]\n",
    "        if scale < threshold:\n",
    "          continue\n",
    "        box_index = TinyYOLOv3.entry_index(params.side, params.coords, params.classes, n * side_square + i, 0)\n",
    "        x = (col + predictions[box_index + 0 * side_square]) / params.side * resized_image_w\n",
    "        y = (row + predictions[box_index + 1 * side_square]) / params.side * resized_image_h\n",
    "        # Value for exp is very big number in some cases so following construction is using here\n",
    "        try:\n",
    "          w_exp = exp(predictions[box_index + 2 * side_square])\n",
    "          h_exp = exp(predictions[box_index + 3 * side_square])\n",
    "        except OverflowError:\n",
    "          continue\n",
    "        w = w_exp * params.anchors[params.anchor_offset + 2 * n]\n",
    "        h = h_exp * params.anchors[params.anchor_offset + 2 * n + 1]\n",
    "        for j in range(params.classes):\n",
    "          class_index = TinyYOLOv3.entry_index(params.side, params.coords, params.classes, n * side_square + i,\n",
    "            params.coords + 1 + j)\n",
    "          confidence = scale * predictions[class_index]\n",
    "          if confidence < threshold:\n",
    "            continue\n",
    "          objects.append(TinyYOLOv3.scale_bbox(x=x, y=y, h=h, w=w, class_id=j, confidence=confidence,\n",
    "            h_scale=orig_im_h / resized_image_h, w_scale=orig_im_w / resized_image_w))\n",
    "    return objects    \n",
    "\n",
    "\n",
    "  def run(self, image):\n",
    "    \"\"\"Runs inference on a single image.\n",
    "\n",
    "    Args:\n",
    "      image: A PIL.Image object, raw input image.\n",
    "\n",
    "    Returns:\n",
    "      resized_image: RGB image resized from original input image.\n",
    "      seg_map: Segmentation map of `resized_image`.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
    "    target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "    resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
    "    batch_seg_map = self.sess.run(\n",
    "        self.OUTPUT_TENSOR_NAME,\n",
    "        feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
    "    seg_map = batch_seg_map[0]\n",
    "    return resized_image, seg_map\n",
    "\n",
    "def vis_segmentation(image, seg_map):\n",
    "  \"\"\"Visualizes input image, segmentation map and overlay view.\"\"\"\n",
    "  plt.figure(figsize=(15, 5))\n",
    "  grid_spec = gridspec.GridSpec(1, 4, width_ratios=[6, 6, 6, 1])\n",
    "\n",
    "  plt.subplot(grid_spec[0])\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')\n",
    "  plt.title('input image')\n",
    "\n",
    "  plt.subplot(grid_spec[1])\n",
    "  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
    "  plt.imshow(seg_image)\n",
    "  plt.axis('off')\n",
    "  plt.title('segmentation map')\n",
    "\n",
    "  plt.subplot(grid_spec[2])\n",
    "  plt.imshow(image)\n",
    "  plt.imshow(seg_image, alpha=0.7)\n",
    "  plt.axis('off')\n",
    "  plt.title('segmentation overlay')\n",
    "\n",
    "  unique_labels = np.unique(seg_map)\n",
    "  ax = plt.subplot(grid_spec[3])\n",
    "  plt.imshow(\n",
    "      FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest')\n",
    "  ax.yaxis.tick_right()\n",
    "  plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n",
    "  plt.xticks([], [])\n",
    "  ax.tick_params(width=0.0)\n",
    "  plt.grid('off')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "LABEL_NAMES = np.asarray([\n",
    "    'background', 'leaf', 'other', 'other', 'other', 'other', 'other',\n",
    "    'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other',\n",
    "    'other', 'other', 'other', 'other', 'other', 'other'\n",
    "])\n",
    "\n",
    "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n",
    "FULL_COLOR_MAP = label_to_color_image(FULL_LABEL_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nGcZzNkASG9A"
   },
   "source": [
    "## Select a pretrained model\n",
    "Select the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-27ee006487b6>:14: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "MODEL = TinyYoloV3Model('pbmodel/yolov3-tiny-leaf-train_best.graph')\n",
    "print('model loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "edGukUHXyymr"
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_visualization(image_path):\n",
    "  \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n",
    "  original_im = Image.open(image_path)\n",
    "\n",
    "  print('running deeplab on image %s...' % image_path)\n",
    "  resized_im, seg_map = MODEL.run(original_im)\n",
    "  print(seg_map[256][256])\n",
    "\n",
    "  vis_segmentation(resized_im, seg_map)\n",
    "\n",
    "\n",
    "with open(\"./data/valid.txt\", \"r\") as f:\n",
    "    testfile = f.readline()[:-1]\n",
    "print(testfile)\n",
    "run_visualization('{0}'.format(testfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export model to tensorboard and start tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "    model_filename =\"pbmodel/yolov3-tiny-leaf-train_best.pb\"\n",
    "    with gfile.FastGFile(model_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        g_in = tf.import_graph_def(graph_def)\n",
    "\n",
    "        sess = tf.Session(graph=g_in)\n",
    "    LOGDIR=\"pbmodel\"\n",
    "    train_writer = tf.summary.FileWriter(LOGDIR)\n",
    "    train_writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6007\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fce00d883c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir pbmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DeepLab Demo.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
